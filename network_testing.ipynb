{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emotion classification\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from src.classifiers.classification_cnn import ClassificationCNN\n",
    "from src.data_utils import get_CIFAR10_datasets, OverfitSampler, rel_error\n",
    "\n",
    "#torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset\n",
    "=========\n",
    "Preprocessing will be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the (preprocessed) CIFAR10 data. The preprocessing includes\n",
    "# channel swapping, normalization and train-val-test splitting.\n",
    "# Loading the datasets might take a while.\n",
    "\n",
    "\"\"\"\n",
    "train_data, val_data, test_data, mean_image = get_CIFAR10_datasets()\n",
    "print(\"Train size: %i\" % len(train_data))\n",
    "print(\"Val size: %i\" % len(val_data))\n",
    "print(\"Test size: %i\" % len(test_data))\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for cls_idx, cls in enumerate(classes):\n",
    "    cls_data = [datum for datum in test_data if datum[1] == cls_idx]\n",
    "    rnd_idxs = np.random.randint(0, len(cls_data), samples_per_class)\n",
    "    rnd_cls_data = [datum for i, datum in enumerate(cls_data) if i in rnd_idxs]\n",
    "    for i, cls_datum in enumerate(rnd_cls_data):\n",
    "        plt_idx = i * num_classes + cls_idx + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(cls_datum[0].numpy().transpose(1,2,0) + mean_image.transpose(1,2,0))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "START TRAIN.\n",
      "[Iteration 10/2200] TRAIN loss: 2.136\n",
      "[Iteration 20/2200] TRAIN loss: 2.054\n",
      "[Iteration 30/2200] TRAIN loss: 2.082\n",
      "[Iteration 40/2200] TRAIN loss: 2.055\n",
      "[Epoch 1/50] TRAIN acc/loss: 0.080/1.860\n",
      "[Epoch 1/50] VAL   acc/loss: 0.038/2.075\n",
      "[Iteration 54/2200] TRAIN loss: 2.010\n",
      "[Iteration 64/2200] TRAIN loss: 2.073\n",
      "[Iteration 74/2200] TRAIN loss: 2.042\n",
      "[Iteration 84/2200] TRAIN loss: 2.059\n",
      "[Epoch 2/50] TRAIN acc/loss: 0.160/1.922\n",
      "[Epoch 2/50] VAL   acc/loss: 0.062/2.016\n"
     ]
    }
   ],
   "source": [
    "from train_classifier import train\n",
    "\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Results\n",
    "Loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(solver.train_loss_history, 'o')\n",
    "plt.plot(range(0, len(solver.val_loss_history) * 19, 19), solver.val_loss_history, '-o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(solver.train_acc_history, '-o')\n",
    "plt.plot(range(0, len(solver.val_acc_history) * 19, 19), solver.val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from src.vis_utils import visualize_grid\n",
    "\n",
    "# first (next) parameter should be convolutional\n",
    "conv_params = next(model.parameters()).data.cpu().numpy()\n",
    "grid = visualize_grid(conv_params.transpose(0, 2, 3, 1))\n",
    "plt.imshow(grid.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.gcf().set_size_inches(6, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=50, shuffle=False, num_workers=4)\n",
    "\n",
    "scores = []\n",
    "for inputs, target in test_loader:\n",
    "    inputs, targets = Variable(inputs), Variable(target)\n",
    "    if model.is_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    preds = preds.type(torch.IntTensor).cpu()\n",
    "    targets = targets.cpu()\n",
    "    scores.extend((preds == targets).data.numpy())\n",
    "    \n",
    "print('Test set accuracy: %f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "\n",
    "When you are satisfied with your training, you can save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"models/classification_cnn.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
