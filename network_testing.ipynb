{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emotion classification\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from src.classifiers.classification_cnn import ClassificationCNN\n",
    "from src.data_utils import get_CIFAR10_datasets, OverfitSampler, rel_error\n",
    "\n",
    "#torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset\n",
    "=========\n",
    "Preprocessing will be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the (preprocessed) CIFAR10 data. The preprocessing includes\n",
    "# channel swapping, normalization and train-val-test splitting.\n",
    "# Loading the datasets might take a while.\n",
    "\n",
    "\"\"\"\n",
    "train_data, val_data, test_data, mean_image = get_CIFAR10_datasets()\n",
    "print(\"Train size: %i\" % len(train_data))\n",
    "print(\"Val size: %i\" % len(val_data))\n",
    "print(\"Test size: %i\" % len(test_data))\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for cls_idx, cls in enumerate(classes):\n",
    "    cls_data = [datum for datum in test_data if datum[1] == cls_idx]\n",
    "    rnd_idxs = np.random.randint(0, len(cls_data), samples_per_class)\n",
    "    rnd_cls_data = [datum for i, datum in enumerate(cls_data) if i in rnd_idxs]\n",
    "    for i, cls_datum in enumerate(rnd_cls_data):\n",
    "        plt_idx = i * num_classes + cls_idx + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(cls_datum[0].numpy().transpose(1,2,0) + mean_image.transpose(1,2,0))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "START TRAIN.\n",
      "[Iteration 10/2200] TRAIN loss: 2.136\n",
      "[Iteration 20/2200] TRAIN loss: 2.054\n",
      "[Iteration 30/2200] TRAIN loss: 2.082\n",
      "[Iteration 40/2200] TRAIN loss: 2.055\n",
      "[Epoch 1/50] TRAIN acc/loss: 0.080/1.860\n",
      "[Epoch 1/50] VAL   acc/loss: 0.038/2.075\n",
      "[Iteration 54/2200] TRAIN loss: 2.010\n",
      "[Iteration 64/2200] TRAIN loss: 2.073\n",
      "[Iteration 74/2200] TRAIN loss: 2.042\n",
      "[Iteration 84/2200] TRAIN loss: 2.059\n",
      "[Epoch 2/50] TRAIN acc/loss: 0.160/1.922\n",
      "[Epoch 2/50] VAL   acc/loss: 0.062/2.016\n",
      "[Iteration 98/2200] TRAIN loss: 2.073\n",
      "[Iteration 108/2200] TRAIN loss: 2.027\n",
      "[Iteration 118/2200] TRAIN loss: 1.976\n",
      "[Iteration 128/2200] TRAIN loss: 2.049\n",
      "[Epoch 3/50] TRAIN acc/loss: 0.120/2.127\n",
      "[Epoch 3/50] VAL   acc/loss: 0.137/2.042\n",
      "[Iteration 142/2200] TRAIN loss: 2.043\n",
      "[Iteration 152/2200] TRAIN loss: 2.008\n",
      "[Iteration 162/2200] TRAIN loss: 2.054\n",
      "[Iteration 172/2200] TRAIN loss: 1.987\n",
      "[Epoch 4/50] TRAIN acc/loss: 0.000/2.176\n",
      "[Epoch 4/50] VAL   acc/loss: 0.038/2.064\n",
      "[Iteration 186/2200] TRAIN loss: 2.029\n",
      "[Iteration 196/2200] TRAIN loss: 2.017\n",
      "[Iteration 206/2200] TRAIN loss: 1.992\n",
      "[Iteration 216/2200] TRAIN loss: 1.969\n",
      "[Epoch 5/50] TRAIN acc/loss: 0.080/1.886\n",
      "[Epoch 5/50] VAL   acc/loss: 0.045/2.058\n",
      "[Iteration 230/2200] TRAIN loss: 1.937\n",
      "[Iteration 240/2200] TRAIN loss: 2.037\n",
      "[Iteration 250/2200] TRAIN loss: 2.018\n",
      "[Iteration 260/2200] TRAIN loss: 1.978\n",
      "[Epoch 6/50] TRAIN acc/loss: 0.040/2.221\n",
      "[Epoch 6/50] VAL   acc/loss: 0.045/2.011\n",
      "[Iteration 274/2200] TRAIN loss: 2.011\n",
      "[Iteration 284/2200] TRAIN loss: 1.995\n",
      "[Iteration 294/2200] TRAIN loss: 1.963\n",
      "[Iteration 304/2200] TRAIN loss: 2.009\n",
      "[Epoch 7/50] TRAIN acc/loss: 0.200/1.888\n",
      "[Epoch 7/50] VAL   acc/loss: 0.108/1.969\n",
      "[Iteration 318/2200] TRAIN loss: 1.870\n",
      "[Iteration 328/2200] TRAIN loss: 1.931\n",
      "[Iteration 338/2200] TRAIN loss: 1.976\n",
      "[Iteration 348/2200] TRAIN loss: 1.927\n",
      "[Epoch 8/50] TRAIN acc/loss: 0.360/1.861\n",
      "[Epoch 8/50] VAL   acc/loss: 0.266/1.923\n",
      "[Iteration 362/2200] TRAIN loss: 1.901\n",
      "[Iteration 372/2200] TRAIN loss: 1.904\n",
      "[Iteration 382/2200] TRAIN loss: 1.799\n",
      "[Iteration 392/2200] TRAIN loss: 1.844\n",
      "[Epoch 9/50] TRAIN acc/loss: 0.120/1.756\n",
      "[Epoch 9/50] VAL   acc/loss: 0.119/1.920\n",
      "[Iteration 406/2200] TRAIN loss: 1.856\n",
      "[Iteration 416/2200] TRAIN loss: 1.876\n",
      "[Iteration 426/2200] TRAIN loss: 1.769\n",
      "[Iteration 436/2200] TRAIN loss: 1.741\n",
      "[Epoch 10/50] TRAIN acc/loss: 0.240/1.666\n",
      "[Epoch 10/50] VAL   acc/loss: 0.105/1.865\n",
      "[Iteration 450/2200] TRAIN loss: 1.698\n",
      "[Iteration 460/2200] TRAIN loss: 1.748\n",
      "[Iteration 470/2200] TRAIN loss: 1.742\n",
      "[Iteration 480/2200] TRAIN loss: 1.876\n",
      "[Epoch 11/50] TRAIN acc/loss: 0.160/1.715\n",
      "[Epoch 11/50] VAL   acc/loss: 0.116/1.804\n",
      "[Iteration 494/2200] TRAIN loss: 1.815\n",
      "[Iteration 504/2200] TRAIN loss: 1.861\n",
      "[Iteration 514/2200] TRAIN loss: 1.810\n",
      "[Iteration 524/2200] TRAIN loss: 1.679\n",
      "[Epoch 12/50] TRAIN acc/loss: 0.520/1.461\n",
      "[Epoch 12/50] VAL   acc/loss: 0.354/1.757\n",
      "[Iteration 538/2200] TRAIN loss: 1.775\n",
      "[Iteration 548/2200] TRAIN loss: 1.753\n",
      "[Iteration 558/2200] TRAIN loss: 1.695\n",
      "[Iteration 568/2200] TRAIN loss: 1.741\n",
      "[Epoch 13/50] TRAIN acc/loss: 0.160/1.264\n",
      "[Epoch 13/50] VAL   acc/loss: 0.098/2.003\n",
      "[Iteration 582/2200] TRAIN loss: 1.794\n",
      "[Iteration 592/2200] TRAIN loss: 1.740\n",
      "[Iteration 602/2200] TRAIN loss: 1.647\n",
      "[Iteration 612/2200] TRAIN loss: 1.639\n",
      "[Epoch 14/50] TRAIN acc/loss: 0.240/1.913\n",
      "[Epoch 14/50] VAL   acc/loss: 0.165/1.837\n",
      "[Iteration 626/2200] TRAIN loss: 1.610\n",
      "[Iteration 636/2200] TRAIN loss: 1.589\n",
      "[Iteration 646/2200] TRAIN loss: 1.586\n",
      "[Iteration 656/2200] TRAIN loss: 1.564\n",
      "[Epoch 15/50] TRAIN acc/loss: 0.360/1.636\n",
      "[Epoch 15/50] VAL   acc/loss: 0.301/1.653\n",
      "[Iteration 670/2200] TRAIN loss: 1.444\n",
      "[Iteration 680/2200] TRAIN loss: 1.557\n",
      "[Iteration 690/2200] TRAIN loss: 1.621\n",
      "[Iteration 700/2200] TRAIN loss: 1.622\n",
      "[Epoch 16/50] TRAIN acc/loss: 0.160/1.968\n",
      "[Epoch 16/50] VAL   acc/loss: 0.245/1.796\n",
      "[Iteration 714/2200] TRAIN loss: 1.658\n",
      "[Iteration 724/2200] TRAIN loss: 1.558\n",
      "[Iteration 734/2200] TRAIN loss: 1.390\n",
      "[Iteration 744/2200] TRAIN loss: 1.547\n",
      "[Epoch 17/50] TRAIN acc/loss: 0.600/1.501\n",
      "[Epoch 17/50] VAL   acc/loss: 0.419/1.710\n",
      "[Iteration 758/2200] TRAIN loss: 1.524\n",
      "[Iteration 768/2200] TRAIN loss: 1.484\n",
      "[Iteration 778/2200] TRAIN loss: 1.495\n",
      "[Iteration 788/2200] TRAIN loss: 1.401\n",
      "[Epoch 18/50] TRAIN acc/loss: 0.280/1.509\n",
      "[Epoch 18/50] VAL   acc/loss: 0.355/1.653\n",
      "[Iteration 802/2200] TRAIN loss: 1.436\n",
      "[Iteration 812/2200] TRAIN loss: 1.493\n",
      "[Iteration 822/2200] TRAIN loss: 1.450\n",
      "[Iteration 832/2200] TRAIN loss: 1.403\n",
      "[Epoch 19/50] TRAIN acc/loss: 0.240/1.310\n",
      "[Epoch 19/50] VAL   acc/loss: 0.153/1.751\n",
      "[Iteration 846/2200] TRAIN loss: 1.433\n",
      "[Iteration 856/2200] TRAIN loss: 1.467\n",
      "[Iteration 866/2200] TRAIN loss: 1.338\n",
      "[Iteration 876/2200] TRAIN loss: 1.614\n",
      "[Epoch 20/50] TRAIN acc/loss: 0.320/1.151\n",
      "[Epoch 20/50] VAL   acc/loss: 0.294/1.690\n",
      "[Iteration 890/2200] TRAIN loss: 1.442\n",
      "[Iteration 900/2200] TRAIN loss: 1.426\n",
      "[Iteration 910/2200] TRAIN loss: 1.313\n",
      "[Iteration 920/2200] TRAIN loss: 1.303\n",
      "[Epoch 21/50] TRAIN acc/loss: 0.360/1.403\n",
      "[Epoch 21/50] VAL   acc/loss: 0.368/1.617\n",
      "[Iteration 934/2200] TRAIN loss: 1.538\n",
      "[Iteration 944/2200] TRAIN loss: 1.536\n",
      "[Iteration 954/2200] TRAIN loss: 1.457\n",
      "[Iteration 964/2200] TRAIN loss: 1.322\n",
      "[Epoch 22/50] TRAIN acc/loss: 0.240/1.759\n",
      "[Epoch 22/50] VAL   acc/loss: 0.242/1.654\n",
      "[Iteration 978/2200] TRAIN loss: 1.399\n",
      "[Iteration 988/2200] TRAIN loss: 1.312\n",
      "[Iteration 998/2200] TRAIN loss: 1.291\n",
      "[Iteration 1008/2200] TRAIN loss: 1.420\n",
      "[Epoch 23/50] TRAIN acc/loss: 0.600/0.895\n",
      "[Epoch 23/50] VAL   acc/loss: 0.353/1.527\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a3b890e57956>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtrain_classifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mU:\\Florian\\Projekte\\EmotionClassification\\train_classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptim_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m5e-5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mtic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_nth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0mtemp_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mU:\\Florian\\Projekte\\EmotionClassification\\src\\solver.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, model, train_loader, val_loader, num_epochs, log_nth)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# ensure that the worker exits on process exit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "from train_classifier import train\n",
    "\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Results\n",
    "Loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(solver.train_loss_history, 'o')\n",
    "plt.plot(range(0, len(solver.val_loss_history) * 19, 19), solver.val_loss_history, '-o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(solver.train_acc_history, '-o')\n",
    "plt.plot(range(0, len(solver.val_acc_history) * 19, 19), solver.val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from src.vis_utils import visualize_grid\n",
    "\n",
    "# first (next) parameter should be convolutional\n",
    "conv_params = next(model.parameters()).data.cpu().numpy()\n",
    "grid = visualize_grid(conv_params.transpose(0, 2, 3, 1))\n",
    "plt.imshow(grid.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.gcf().set_size_inches(6, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=50, shuffle=False, num_workers=4)\n",
    "\n",
    "scores = []\n",
    "for inputs, target in test_loader:\n",
    "    inputs, targets = Variable(inputs), Variable(target)\n",
    "    if model.is_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    preds = preds.type(torch.IntTensor).cpu()\n",
    "    targets = targets.cpu()\n",
    "    scores.extend((preds == targets).data.numpy())\n",
    "    \n",
    "print('Test set accuracy: %f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "\n",
    "When you are satisfied with your training, you can save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"models/classification_cnn.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
